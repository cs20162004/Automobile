{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nX = pd.read_csv(\"/kaggle/input/imports-85.csv\", header = None)\ncolumns = {\n    0: 'symboling',\n    1: 'normalized-losses',\n    2: 'make',\n    3: 'fuel-type',\n    4: 'aspiration',\n    5: 'num-of-doors',\n    6: 'body-style',\n    7: 'drive-wheels',\n    8: 'engine-location',\n    9: 'wheel-base',\n    10: 'length',\n    11: 'width',\n    12: 'height',\n    13: 'curb-weight',\n    14: 'engine-type',\n    15: 'num-of-cylinders',\n    16: 'engine-size',\n    17: 'fuel-system',\n    18: 'bore',\n    19: 'stroke',\n    20: 'compression-ratio',\n    21: 'horsepower',\n    22: 'peak-rpm',\n    23: 'city-mpg',\n    24: 'highway-mpg',\n    25: 'price'\n}\nX.rename(columns = columns, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.shape)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X[X['normalized-losses'] != '?']     #Skip samples with missing values in the target 'normalized_losses'\nprint(X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.drop('symboling', axis = 1, inplace = True)     # drop 'symboling' column\n\nX.replace('?', np.nan, inplace = True)            # replace missing values with np.nan\n\nX.isnull().sum()       # check for number of missing values in the data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert columns with 'int' or 'float' values, having object dtype, back to int and float dtype\n\nX['normalized-losses'] = X['normalized-losses'].astype(str).astype(int)\nX['bore'] = X['bore'].astype(str).astype(float)\nX['stroke'] = X['stroke'].astype(str).astype(float)\nX['horsepower'] = X['horsepower'].astype(str).astype(int)\nX['peak-rpm'] = X['peak-rpm'].astype(str).astype(int)\nX['price'] = X['price'].astype(str).astype(int)\n\nX['num-of-doors'] = X['num-of-doors'].map({'two' : 2, 'four' : 4})\n\nX.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X['bore'].fillna(X['bore'].mean(), inplace = True)\n#X['stroke'].fillna(X['stroke'].mean(), inplace = True)\nX = X.fillna(X.mode().iloc[0])     #Fill missing values with the most frequent value of that column","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Encode categorical variables into numerical"},{"metadata":{"trusted":true},"cell_type":"code","source":"X.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encode_cols = ['make']\none_hot_cols = ['fuel-type', 'aspiration', 'body-style', 'drive-wheels', 'engine-location', 'engine-type', 'num-of-cylinders', 'fuel-system']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\nlabel_encoder = LabelEncoder()\nOne_encoder = OneHotEncoder(handle_unknown='ignore', sparse = False)\n\nlabel_X = X.copy()\n\nfor cols in encode_cols:\n    label_X[cols] = label_encoder.fit_transform(X[cols])\n    \nOH_cols = pd.DataFrame(One_encoder.fit_transform(label_X[one_hot_cols]))\nOH_cols.index = label_X.index\nOH_X = label_X.drop(one_hot_cols, axis = 1)\n\nnum_X = pd.concat([OH_X, OH_cols], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(num_X['price'], num_X['normalized-losses'], color = 'green')\nplt.xlabel('price')\nplt.ylabel('normalized_losses')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split the data into training and testing datas"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(num_X, test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y = train['normalized-losses']\ntrain_x = train.drop('normalized-losses', axis = 1)\n\ntest_y = test['normalized-losses']\ntest_x = test.drop('normalized-losses', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling using *LinearRegression* model from *sklearn*"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\n\nmodel.fit(train_x, train_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Evaluation**\n\nCalculating model's accuracy using MSE (Mean Squared Error) metric"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\ny_pred = model.predict(test_x)\n\nprint(metrics.mean_squared_error(test_y, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_pred = model.predict(train_x.sort_values('price'))\nplt.scatter(train_x['price'], train_y, color = 'blue')\nplt.plot(train_x.sort_values('price'), x_pred)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RandomForestRegressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nmodel1 = RandomForestRegressor(n_estimators=100, random_state=0)\nmodel1.fit(train_x, train_y)\npreds = model1.predict(test_x)\nprint(metrics.mean_squared_error(test_y, preds))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}